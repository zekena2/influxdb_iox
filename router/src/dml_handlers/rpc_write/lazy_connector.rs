//! A lazy connector for Tonic gRPC [`Channel`] instances.

use std::{
    sync::{
        atomic::{AtomicUsize, Ordering},
        Arc,
    },
    time::Duration,
};

use async_trait::async_trait;
use generated_types::influxdata::iox::ingester::v1::{
    write_service_client::WriteServiceClient, WriteRequest,
};
use observability_deps::tracing::*;
use parking_lot::Mutex;
use tokio::task::JoinHandle;
use tonic::{
    metadata::AsciiMetadataValue,
    transport::{Channel, Endpoint},
    Code,
};
use trace::ctx::SpanContext;

use super::client::{RpcWriteClientError, TracePropagatingWriteClient, WriteClient};

const RETRY_INTERVAL: Duration = Duration::from_secs(1);
const CONNECT_TIMEOUT: Duration = Duration::from_secs(1);

/// How many consecutive errors must be observed before opening a new connection
/// (at most once per [`RETRY_INTERVAL]).
const RECONNECT_ERROR_COUNT: usize = 10;

/// Define a safe maximum ingester write response size.
const MAX_INCOMING_MSG_BYTES: usize = 1024 * 1024; // 1 MiB

/// Lazy [`Channel`] connector.
///
/// Connections are attempted in a background thread every [`RETRY_INTERVAL`].
/// once a connection has been established, the [`Channel`] internally handles
/// reconnections as needed.
///
/// Returns [`RpcWriteClientError::UpstreamNotConnected`] when no connection is
/// available.
#[derive(Debug)]
pub struct LazyConnector {
    addr: Endpoint,
    connection: Arc<Mutex<Option<Channel>>>,

    /// The maximum outgoing message size.
    ///
    /// The incoming size remains bounded at [`MAX_INCOMING_MSG_BYTES`] as the
    /// ingester SHOULD NOT ever generate a response larger than this.
    max_outgoing_msg_bytes: usize,

    /// The number of request errors observed without a single success.
    consecutive_errors: Arc<AtomicUsize>,
    /// A task that periodically opens a new connection to `addr` when
    /// `consecutive_errors` is more than [`RECONNECT_ERROR_COUNT`].
    connection_task: JoinHandle<()>,

    trace_context_header_name: String,
}

impl LazyConnector {
    /// Lazily connect to `addr`.
    pub fn new(
        addr: Endpoint,
        request_timeout: Duration,
        max_outgoing_msg_bytes: usize,
        trace_context_header_name: String,
    ) -> Self {
        let addr = addr
            .connect_timeout(CONNECT_TIMEOUT)
            .timeout(request_timeout);
        let connection = Default::default();

        // Drive first connection by setting it above the connection limit.
        let consecutive_errors = Arc::new(AtomicUsize::new(RECONNECT_ERROR_COUNT + 1));
        Self {
            addr: addr.clone(),
            max_outgoing_msg_bytes,
            connection: Arc::clone(&connection),
            connection_task: tokio::spawn(try_connect(
                addr,
                connection,
                Arc::clone(&consecutive_errors),
            )),
            consecutive_errors,
            trace_context_header_name,
        }
    }

    /// Returns `true` if a connection was established at some point in the
    /// past.
    ///
    /// If true, the connection may be active and healthy, or currently
    /// unusable.
    pub fn did_connect(&self) -> bool {
        self.connection.lock().is_some()
    }
}

#[async_trait]
impl WriteClient for LazyConnector {
    async fn write(
        &self,
        op: WriteRequest,
        span_ctx: Option<SpanContext>,
    ) -> Result<(), RpcWriteClientError> {
        let conn = self.connection.lock().clone();
        let conn = conn.ok_or_else(|| {
            RpcWriteClientError::UpstreamNotConnected(self.addr.uri().to_string())
        })?;

        match TracePropagatingWriteClient::new(
            WriteServiceClient::new(conn)
                .max_encoding_message_size(self.max_outgoing_msg_bytes)
                .max_decoding_message_size(MAX_INCOMING_MSG_BYTES),
            &self.trace_context_header_name,
        )
        .write(op, span_ctx)
        .await
        {
            Err(e) if is_envoy_unavailable_error(&e) => {
                warn!(error=%e, "detected envoy proxy upstream network error translation, reconnecting");
                self.consecutive_errors
                    .store(RECONNECT_ERROR_COUNT + 1, Ordering::Relaxed);
                return Err(e);
            }
            Err(e) => {
                self.consecutive_errors.fetch_add(1, Ordering::Relaxed);
                return Err(e);
            }
            Ok(_) => {
                self.consecutive_errors.store(0, Ordering::Relaxed);
                Ok(())
            }
        }
    }
}

/// Returns `true` if `e` is a gRPC error with the status [`Code::Unavailable`],
/// and a metadata entry indicating the response was generated by an envoy proxy
/// instance.
///
/// This is needed because the envoy proxy effectively converts network errors
/// (dial & I/O errors) into application-level (gRPC) errors, much like a pure
/// HTTP proxy would. Unfortunately this is a breaking change in behaviour for
/// networking code like [`tonic`]'s transport implementation, which can no
/// longer easily differentiate network errors from actual application errors.
fn is_envoy_unavailable_error(e: &RpcWriteClientError) -> bool {
    match e {
        RpcWriteClientError::Upstream(e) if e.code() == Code::Unavailable => e
            .metadata()
            .get("server")
            .map(|v| v == AsciiMetadataValue::from_static("envoy"))
            .unwrap_or(false),
        RpcWriteClientError::Upstream(_) => false,
        RpcWriteClientError::MisconfiguredMetadataKey(_) => false,
        RpcWriteClientError::MisconfiguredMetadataValue(_) => false,
        RpcWriteClientError::UpstreamNotConnected(_) => unreachable!(),
    }
}

impl Drop for LazyConnector {
    fn drop(&mut self) {
        self.connection_task.abort();
    }
}

async fn try_connect(
    addr: Endpoint,
    connection: Arc<Mutex<Option<Channel>>>,
    consecutive_errors: Arc<AtomicUsize>,
) {
    loop {
        if consecutive_errors.load(Ordering::Relaxed) > RECONNECT_ERROR_COUNT {
            match addr.connect().await {
                Ok(v) => {
                    info!(endpoint = %addr.uri(), "connected to upstream ingester");
                    *connection.lock() = Some(v);
                    consecutive_errors.store(0, Ordering::Relaxed);
                }
                Err(e) => warn!(
                    endpoint = %addr.uri(),
                    error=%e,
                    "failed to connect to upstream ingester"
                ),
            }
        }
        tokio::time::sleep(RETRY_INTERVAL).await;
    }
}
